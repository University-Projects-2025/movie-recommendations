{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T12:45:36.969291Z",
     "iopub.status.busy": "2025-11-21T12:45:36.968544Z",
     "iopub.status.idle": "2025-11-21T17:03:11.299809Z",
     "shell.execute_reply": "2025-11-21T17:03:11.298893Z",
     "shell.execute_reply.started": "2025-11-21T12:45:36.969258Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "n_users=162541, n_items=59047, n_nodes=221588\n",
      "Adjacency normalized and converted to sparse tensor.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 9766/9766 [49:07<00:00,  3.31it/s, batch_loss=0.1157]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss sum: 1354.1573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 evaluation: ROC-AUC=0.9414, Precision@50=0.1332, Recall@50=0.1132\n",
      "*** Saved new best model at epoch 1 with ROC-AUC=0.9414 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 9766/9766 [49:04<00:00,  3.32it/s, batch_loss=0.1112]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss sum: 1062.8026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 evaluation: ROC-AUC=0.9457, Precision@50=0.1434, Recall@50=0.1236\n",
      "*** Saved new best model at epoch 2 with ROC-AUC=0.9457 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 9766/9766 [49:04<00:00,  3.32it/s, batch_loss=0.1010]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss sum: 961.7361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 evaluation: ROC-AUC=0.9456, Precision@50=0.1473, Recall@50=0.1267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 9766/9766 [49:02<00:00,  3.32it/s, batch_loss=0.0816]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss sum: 906.8385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 evaluation: ROC-AUC=0.9484, Precision@50=0.1505, Recall@50=0.1287\n",
      "*** Saved new best model at epoch 4 with ROC-AUC=0.9484 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 9766/9766 [49:04<00:00,  3.32it/s, batch_loss=0.1011]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss sum: 867.9758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 evaluation: ROC-AUC=0.9461, Precision@50=0.1497, Recall@50=0.1294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final evaluation metrics:\n",
      "  roc_auc: 0.946133\n",
      "  precision@50: 0.149672\n",
      "  recall@50: 0.129430\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "data_dir = \"/kaggle/input/movie-lens/\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Hyperparams\n",
    "EMB_DIM = 64\n",
    "NGCF_LAYERS = [64, 64]\n",
    "BATCH_SIZE = 2048\n",
    "EPOCHS = 5\n",
    "LR = 1e-3\n",
    "EVAL_BATCH = 256\n",
    "NEG_PER_POS = 1\n",
    "ROC_NEG_SAMPLES = 100\n",
    "TOPK = 50\n",
    "\n",
    "\n",
    "train_matrix = sp.load_npz(os.path.join(data_dir, 'train_matrix.npz'))\n",
    "test_matrix  = sp.load_npz(os.path.join(data_dir, 'test_matrix.npz'))\n",
    "adj_matrix   = sp.load_npz(os.path.join(data_dir, 'adj_matrix.npz'))\n",
    "user_to_idx  = np.load(os.path.join(data_dir, 'user_to_idx.npy'), allow_pickle=True).item()\n",
    "movie_to_idx = np.load(os.path.join(data_dir, 'movie_to_idx.npy'), allow_pickle=True).item()\n",
    "\n",
    "n_users, n_items = train_matrix.shape\n",
    "n_nodes = n_users + n_items\n",
    "print(f\"n_users={n_users}, n_items={n_items}, n_nodes={n_nodes}\")\n",
    "\n",
    "\n",
    "def convert_sp_mat_to_sp_tensor(X):\n",
    "    coo = X.tocoo()\n",
    "    idx = np.vstack([coo.row, coo.col]).astype(np.int64)\n",
    "    indices = torch.from_numpy(idx)\n",
    "    values = torch.from_numpy(coo.data.astype(np.float32))\n",
    "    return torch.sparse_coo_tensor(indices, values, X.shape).coalesce()\n",
    "\n",
    "def normalize_adj(adj):\n",
    "    adj = adj + sp.eye(adj.shape[0])\n",
    "    rowsum = np.array(adj.sum(1)).flatten()\n",
    "    d_inv_sqrt = np.power(rowsum, -0.5)\n",
    "    d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n",
    "    D_inv_sqrt = sp.diags(d_inv_sqrt)\n",
    "    return D_inv_sqrt.dot(adj).dot(D_inv_sqrt)\n",
    "\n",
    "norm_adj = normalize_adj(adj_matrix)\n",
    "norm_adj_tensor = convert_sp_mat_to_sp_tensor(norm_adj).to(device)\n",
    "print(\"Adjacency normalized and converted to sparse tensor.\")\n",
    "\n",
    "\n",
    "class NGCF(nn.Module):\n",
    "    def __init__(self, n_users, n_items, adj, emb_dim=64, layers=[64,64]):\n",
    "        super().__init__()\n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items\n",
    "        self.n_nodes = n_users + n_items\n",
    "        self.adj = adj\n",
    "\n",
    "        self.embedding = nn.Embedding(self.n_nodes, emb_dim)\n",
    "        nn.init.xavier_uniform_(self.embedding.weight)\n",
    "\n",
    "        self.W_msg = nn.ModuleList()\n",
    "        self.W_self = nn.ModuleList()\n",
    "        prev = emb_dim\n",
    "        for ldim in layers:\n",
    "            self.W_msg.append(nn.Linear(prev, ldim))\n",
    "            self.W_self.append(nn.Linear(prev, ldim))\n",
    "            prev = ldim\n",
    "\n",
    "    def propagate(self, x):\n",
    "        all_embeds = [x]\n",
    "        h = x\n",
    "        for Wm, Ws in zip(self.W_msg, self.W_self):\n",
    "            h_neigh = torch.sparse.mm(self.adj, h)\n",
    "            msg = Wm(h_neigh)\n",
    "            self_trans = Ws(h)\n",
    "            h = F.leaky_relu(msg + self_trans)\n",
    "            all_embeds.append(h)\n",
    "        return torch.cat(all_embeds, dim=1)\n",
    "\n",
    "    def forward_emb(self):\n",
    "        x = self.embedding.weight\n",
    "        return self.propagate(x)\n",
    "\n",
    "    def predict_logits(self, users, items):\n",
    "        emb = self.forward_emb()\n",
    "        user_emb = emb[users]\n",
    "        item_emb = emb[self.n_users + items]\n",
    "        return (user_emb * item_emb).sum(dim=1)\n",
    "\n",
    "\n",
    "class LinkTrainDataset(Dataset):\n",
    "    def __init__(self, train_sp):\n",
    "        self.train = train_sp.tolil()\n",
    "        self.n_users, self.n_items = train_sp.shape\n",
    "        self.pos_pairs = [(u,i) for u in range(self.n_users) for i in self.train.rows[u]]\n",
    "        self.user_pos_set = {u: set(self.train.rows[u]) for u in range(self.n_users)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pos_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        u, i_pos = self.pos_pairs[idx]\n",
    "        while True:\n",
    "            i_neg = np.random.randint(0, self.n_items)\n",
    "            if i_neg not in self.user_pos_set[u]:\n",
    "                break\n",
    "        return u, i_pos, i_neg\n",
    "\n",
    "\n",
    "def expand_batch(batch):\n",
    "    users_pos = batch[0].numpy() if isinstance(batch[0], torch.Tensor) else np.array(batch[0])\n",
    "    pos_items = batch[1].numpy() if isinstance(batch[1], torch.Tensor) else np.array(batch[1])\n",
    "    neg_items = batch[2].numpy() if isinstance(batch[2], torch.Tensor) else np.array(batch[2])\n",
    "\n",
    "    users = np.concatenate([users_pos, users_pos], axis=0)\n",
    "    items = np.concatenate([pos_items, neg_items], axis=0)\n",
    "    labels = np.concatenate([np.ones(len(pos_items), dtype=np.float32),\n",
    "                             np.zeros(len(neg_items), dtype=np.float32)], axis=0)\n",
    "    perm = np.random.permutation(len(users))\n",
    "    return (torch.from_numpy(users[perm]).long(),\n",
    "            torch.from_numpy(items[perm]).long(),\n",
    "            torch.from_numpy(labels[perm]).float())\n",
    "\n",
    "\n",
    "def evaluate_metrics(model, train_sp, test_sp, topk=TOPK, eval_batch=EVAL_BATCH,\n",
    "                     roc_neg_samples=ROC_NEG_SAMPLES, device=device):\n",
    "    model.eval()\n",
    "    train_lil = train_sp.tolil()\n",
    "    test_lil = test_sp.tolil()\n",
    "    with torch.no_grad():\n",
    "        full_emb = model.forward_emb().to(device)\n",
    "        user_emb = full_emb[:n_users]\n",
    "        item_emb = full_emb[n_users:]\n",
    "\n",
    "    # ROC-AUC\n",
    "    roc_scores, roc_labels = [], []\n",
    "    users_with_test = [u for u in range(n_users) if len(test_lil.rows[u]) > 0]\n",
    "    for u in tqdm(users_with_test, desc=\"ROC-AUC sampling\", leave=False):\n",
    "        test_items = test_lil.rows[u]\n",
    "        if len(test_items) == 0: continue\n",
    "        u_emb = user_emb[u].unsqueeze(0)\n",
    "        pos_items_t = torch.tensor(test_items, dtype=torch.long).to(device)\n",
    "        pos_logits = (u_emb * item_emb[pos_items_t]).sum(dim=1).cpu().numpy()\n",
    "        roc_scores.extend(pos_logits.tolist())\n",
    "        roc_labels.extend([1]*len(pos_logits))\n",
    "\n",
    "        forbidden = set(train_lil.rows[u]).union(test_lil.rows[u])\n",
    "        pool = [i for i in range(n_items) if i not in forbidden]\n",
    "        if len(pool) == 0: pool = [i for i in range(n_items) if i not in set(train_lil.rows[u])]\n",
    "        if len(pool) == 0: continue\n",
    "        n_negs = min(len(pool), max(roc_neg_samples, len(pos_items_t)*roc_neg_samples))\n",
    "        neg_sample = np.random.choice(pool, size=n_negs, replace=False)\n",
    "        neg_items_t = torch.tensor(neg_sample, dtype=torch.long).to(device)\n",
    "        neg_logits = (u_emb * item_emb[neg_items_t]).sum(dim=1).cpu().numpy()\n",
    "        roc_scores.extend(neg_logits.tolist())\n",
    "        roc_labels.extend([0]*len(neg_logits))\n",
    "\n",
    "    try:\n",
    "        roc_auc = roc_auc_score(roc_labels, roc_scores)\n",
    "    except: roc_auc = float('nan')\n",
    "\n",
    "    # Precision@K and Recall@K\n",
    "    precisions, recalls = [], []\n",
    "    user_indices = [u for u in range(n_users) if len(test_lil.rows[u])>0]\n",
    "    n_batches = math.ceil(len(user_indices)/eval_batch)\n",
    "    for b in tqdm(range(n_batches), desc=\"Ranking eval\", leave=False):\n",
    "        batch_users = user_indices[b*eval_batch:(b+1)*eval_batch]\n",
    "        if not batch_users: continue\n",
    "        u_emb_batch = user_emb[batch_users]\n",
    "        scores = u_emb_batch @ item_emb.T\n",
    "        for i_idx, u in enumerate(batch_users):\n",
    "            titems = train_lil.rows[u]\n",
    "            if len(titems)>0:\n",
    "                scores[i_idx, titems] = -1e9\n",
    "        topk_vals, topk_idx = torch.topk(scores, topk, dim=1)\n",
    "        topk_idx = topk_idx.cpu().numpy()\n",
    "        for i_idx, u in enumerate(batch_users):\n",
    "            pred = topk_idx[i_idx]\n",
    "            true_set = set(test_lil.rows[u])\n",
    "            if len(true_set)==0: continue\n",
    "            hits = len(set(pred) & true_set)\n",
    "            precisions.append(hits/float(topk))\n",
    "            recalls.append(hits/float(len(true_set)))\n",
    "\n",
    "    precision_at_k = float(np.mean(precisions)) if precisions else 0.0\n",
    "    recall_at_k = float(np.mean(recalls)) if recalls else 0.0\n",
    "    return {\"roc_auc\": roc_auc, f\"precision@{topk}\": precision_at_k, f\"recall@{topk}\": recall_at_k}\n",
    "\n",
    "\n",
    "dataset = LinkTrainDataset(train_matrix)\n",
    "train_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
    "model = NGCF(n_users, n_items, norm_adj_tensor, emb_dim=EMB_DIM, layers=NGCF_LAYERS).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "best_roc_auc = 0.0\n",
    "save_path = \"best_ngcf_model.pth\"\n",
    "\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch}/{EPOCHS}\", leave=True)\n",
    "    for batch in pbar:\n",
    "        u_batch, pos_batch, neg_batch = batch\n",
    "        u_batch, i_batch, y_batch = expand_batch((u_batch, pos_batch, neg_batch))\n",
    "        u_batch, i_batch, y_batch = u_batch.to(device), i_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        logits = model.predict_logits(u_batch, i_batch)\n",
    "        loss = loss_fn(logits, y_batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        pbar.set_postfix({\"batch_loss\": f\"{loss.item():.4f}\"})\n",
    "\n",
    "    print(f\"Epoch {epoch} Loss sum: {total_loss:.4f}\")\n",
    "\n",
    "    # Evaluation\n",
    "    metrics = evaluate_metrics(model, train_matrix, test_matrix, topk=TOPK, eval_batch=EVAL_BATCH)\n",
    "    roc_auc = metrics[\"roc_auc\"]\n",
    "    precision = metrics[f\"precision@{TOPK}\"]\n",
    "    recall = metrics[f\"recall@{TOPK}\"]\n",
    "    print(f\"Epoch {epoch} evaluation: ROC-AUC={roc_auc:.4f}, Precision@{TOPK}={precision:.4f}, Recall@{TOPK}={recall:.4f}\")\n",
    "\n",
    "    # Autosave\n",
    "    if roc_auc > best_roc_auc:\n",
    "        best_roc_auc = roc_auc\n",
    "        torch.save({\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            \"roc_auc\": roc_auc,\n",
    "            \"precision@k\": precision,\n",
    "            \"recall@k\": recall\n",
    "        }, save_path)\n",
    "        print(f\"*** Saved new best model at epoch {epoch} with ROC-AUC={roc_auc:.4f} ***\")\n",
    "\n",
    "# Final evaluation\n",
    "metrics = evaluate_metrics(model, train_matrix, test_matrix, topk=TOPK, eval_batch=EVAL_BATCH)\n",
    "print(\"Final evaluation metrics:\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"  {k}: {v:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T18:36:46.803243Z",
     "iopub.status.busy": "2025-11-21T18:36:46.802587Z",
     "iopub.status.idle": "2025-11-21T18:36:55.900313Z",
     "shell.execute_reply": "2025-11-21T18:36:55.899638Z",
     "shell.execute_reply.started": "2025-11-21T18:36:46.803220Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ratings_df = pd.read_csv(\"/kaggle/input/movie-lens/ratings.csv\")\n",
    "movies_df  = pd.read_csv(\"/kaggle/input/movie-lens/movies.csv\")\n",
    "\n",
    "movieId_to_title = dict(zip(movies_df[\"movieId\"], movies_df[\"title\"]))\n",
    "\n",
    "item_idx_to_name = {\n",
    "    idx: movieId_to_title.get(movieId, f\"Unknown movie {movieId}\")\n",
    "    for movieId, idx in movie_to_idx.items()\n",
    "}\n",
    "\n",
    "\n",
    "def get_top_rated_movies(user_id_internal, top_n=5):\n",
    "    \"\"\"Return the user's top-N highest rated movies using ratings.csv.\"\"\"\n",
    "    # Convert internal id → real MovieLens userId\n",
    "    real_user_id = idx_to_user[user_id_internal]\n",
    "    \n",
    "    # Get all user ratings\n",
    "    user_ratings = ratings_df[ratings_df[\"userId\"] == real_user_id]\n",
    "\n",
    "    if user_ratings.empty:\n",
    "        return []\n",
    "\n",
    "    # Sort by rating descending\n",
    "    user_ratings = user_ratings.sort_values(\"rating\", ascending=False)\n",
    "\n",
    "    # Take top N\n",
    "    top = user_ratings.head(top_n)\n",
    "\n",
    "    favorites = []\n",
    "    for _, row in top.iterrows():\n",
    "        movieId = row[\"movieId\"]\n",
    "        rating  = row[\"rating\"]\n",
    "\n",
    "        # Map movieId → internal item index (if exists)\n",
    "        if movieId in movie_to_idx:\n",
    "            item_idx = movie_to_idx[movieId]\n",
    "            title = movieId_to_title.get(movieId, f\"Unknown {movieId}\")\n",
    "            favorites.append((item_idx, title, rating))\n",
    "\n",
    "    return favorites\n",
    "\n",
    "\n",
    "def recommend_for_user(model, user_id_internal, train_matrix, k=20):\n",
    "    model.eval()\n",
    "\n",
    "    # User’s top 5 rated movies (from ratings.csv)\n",
    "    favorites = get_top_rated_movies(user_id_internal, top_n=10)\n",
    "\n",
    "    # Model predictions for unseen items\n",
    "    with torch.no_grad():\n",
    "        full_emb = model.forward_emb().to(device)\n",
    "        user_emb = full_emb[:n_users]\n",
    "        item_emb = full_emb[n_users:]\n",
    "\n",
    "        u_emb = user_emb[user_id_internal].unsqueeze(0)\n",
    "        scores = (u_emb @ item_emb.T).squeeze(0)\n",
    "\n",
    "        # Mask seen interactions\n",
    "        seen_items = set(train_matrix[user_id_internal].nonzero()[1])\n",
    "        for iid in seen_items:\n",
    "            scores[iid] = -1e9\n",
    "\n",
    "        topk_values, topk_indices = torch.topk(scores, k)\n",
    "        top_items = topk_indices.cpu().numpy()\n",
    "        top_scores = topk_values.cpu().numpy()\n",
    "\n",
    "    recommendations = []\n",
    "    for iid, score in zip(top_items, top_scores):\n",
    "        real_movie_id = idx_to_movie[iid]\n",
    "        title = movieId_to_title.get(real_movie_id, f\"Unknown {real_movie_id}\")\n",
    "        recommendations.append((iid, title, float(score)))\n",
    "\n",
    "    return favorites, recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T18:42:14.176478Z",
     "iopub.status.busy": "2025-11-21T18:42:14.176180Z",
     "iopub.status.idle": "2025-11-21T18:42:14.288329Z",
     "shell.execute_reply": "2025-11-21T18:42:14.287360Z",
     "shell.execute_reply.started": "2025-11-21T18:42:14.176457Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Top 5 Highest-Rated Movies by User ===\n",
      "Star Wars: Episode IV - A New Hope (1977)  — rated 5.0\n",
      "Titanic (1997)  — rated 5.0\n",
      "Life Is Beautiful (La Vita è bella) (1997)  — rated 5.0\n",
      "Her (2013)  — rated 5.0\n",
      "Birdman: Or (The Unexpected Virtue of Ignorance) (2014)  — rated 5.0\n",
      "Inside Out (2015)  — rated 5.0\n",
      "Wolf of Wall Street, The (2013)  — rated 5.0\n",
      "Joker (2019)  — rated 4.5\n",
      "Django Unchained (2012)  — rated 4.5\n",
      "Shutter Island (2010)  — rated 4.5\n",
      "\n",
      "=== Model Recommendations ===\n",
      "Dark Knight, The (2008)  — score 6.8265\n",
      "Lord of the Rings: The Fellowship of the Ring, The (2001)  — score 6.3899\n",
      "Lord of the Rings: The Return of the King, The (2003)  — score 6.2539\n",
      "Matrix, The (1999)  — score 6.1014\n",
      "Lord of the Rings: The Two Towers, The (2002)  — score 6.0480\n",
      "Shawshank Redemption, The (1994)  — score 6.0019\n",
      "Inception (2010)  — score 5.9243\n",
      "Fight Club (1999)  — score 5.8044\n",
      "WALL·E (2008)  — score 5.7907\n",
      "Star Wars: Episode IV - A New Hope (1977)  — score 5.7146\n",
      "Forrest Gump (1994)  — score 5.5973\n",
      "Shrek (2001)  — score 5.5910\n",
      "Pirates of the Caribbean: The Curse of the Black Pearl (2003)  — score 5.5639\n",
      "Star Wars: Episode VI - Return of the Jedi (1983)  — score 5.4538\n",
      "Monsters, Inc. (2001)  — score 5.4226\n",
      "Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981)  — score 5.4161\n",
      "Up (2009)  — score 5.4120\n",
      "Finding Nemo (2003)  — score 5.4084\n",
      "Star Wars: Episode V - The Empire Strikes Back (1980)  — score 5.3698\n",
      "Iron Man (2008)  — score 5.3579\n"
     ]
    }
   ],
   "source": [
    "user_id = 162000  # internal index\n",
    "\n",
    "favorites, recommendations = recommend_for_user(\n",
    "    model=model,\n",
    "    user_id_internal=user_id,\n",
    "    train_matrix=train_matrix,\n",
    "    k=20\n",
    ")\n",
    "\n",
    "print(\"=== Top 5 Highest-Rated Movies by User ===\")\n",
    "for iid, title, rating in favorites:\n",
    "    print(f\"{title}  — rated {rating}\")\n",
    "\n",
    "print(\"\\n=== Model Recommendations ===\")\n",
    "for iid, title, score in recommendations:\n",
    "    print(f\"{title}  — score {score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8791811,
     "sourceId": 13820589,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv (3.12.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
