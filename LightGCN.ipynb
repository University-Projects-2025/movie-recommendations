{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b3c0e85",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2025-12-02T19:37:17.868013Z",
          "iopub.status.busy": "2025-12-02T19:37:17.867704Z",
          "iopub.status.idle": "2025-12-02T20:11:14.862402Z",
          "shell.execute_reply": "2025-12-02T20:11:14.861237Z"
        },
        "papermill": {
          "duration": 2037.001026,
          "end_time": "2025-12-02T20:11:14.864378",
          "exception": false,
          "start_time": "2025-12-02T19:37:17.863352",
          "status": "completed"
        },
        "tags": [],
        "id": "8b3c0e85",
        "outputId": "1106a269-867f-4300-eac0-ba4c14fb7110"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torch_sparse\r\n",
            "  Downloading torch_sparse-0.6.18.tar.gz (209 kB)\r\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.0/210.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch_sparse) (1.15.3)\r\n",
            "Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy->torch_sparse) (1.26.4)\r\n",
            "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy->torch_sparse) (1.3.8)\r\n",
            "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy->torch_sparse) (1.2.4)\r\n",
            "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy->torch_sparse) (0.1.1)\r\n",
            "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy->torch_sparse) (2025.3.0)\r\n",
            "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy->torch_sparse) (2022.3.0)\r\n",
            "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy->torch_sparse) (2.4.1)\r\n",
            "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.5,>=1.23.5->scipy->torch_sparse) (2025.3.0)\r\n",
            "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.5,>=1.23.5->scipy->torch_sparse) (2024.2.0)\r\n",
            "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.5,>=1.23.5->scipy->torch_sparse) (2022.3.0)\r\n",
            "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.5,>=1.23.5->scipy->torch_sparse) (1.4.0)\r\n",
            "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.5,>=1.23.5->scipy->torch_sparse) (2024.2.0)\r\n",
            "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.5,>=1.23.5->scipy->torch_sparse) (2024.2.0)\r\n",
            "Building wheels for collected packages: torch_sparse\r\n",
            "  Building wheel for torch_sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
            "  Created wheel for torch_sparse: filename=torch_sparse-0.6.18-cp311-cp311-linux_x86_64.whl size=2847711 sha256=da04e0b8b84680834c3405df36f4eb2052aadb6f84db86939977d13ef9d75528\r\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/e2/1e/299c596063839303657c211f587f05591891cc6cf126d94d21\r\n",
            "Successfully built torch_sparse\r\n",
            "Installing collected packages: torch_sparse\r\n",
            "Successfully installed torch_sparse-0.6.18\r\n",
            "Collecting torch_scatter\r\n",
            "  Downloading torch_scatter-2.1.2.tar.gz (108 kB)\r\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
            "Building wheels for collected packages: torch_scatter\r\n",
            "  Building wheel for torch_scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
            "  Created wheel for torch_scatter: filename=torch_scatter-2.1.2-cp311-cp311-linux_x86_64.whl size=3622745 sha256=5d2bcb00030e27c328231da1c4d0ef15abd7722160f65a6857d16d892eb033cd\r\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/d4/0e/a80af2465354ea7355a2c153b11af2da739cfcf08b6c0b28e2\r\n",
            "Successfully built torch_scatter\r\n",
            "Installing collected packages: torch_scatter\r\n",
            "Successfully installed torch_scatter-2.1.2\r\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Install libraries\n",
        "!pip install torch_sparse\n",
        "!pip install torch_scatter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "161f407f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-02T20:11:14.873589Z",
          "iopub.status.busy": "2025-12-02T20:11:14.873280Z",
          "iopub.status.idle": "2025-12-02T20:11:20.750018Z",
          "shell.execute_reply": "2025-12-02T20:11:20.749210Z"
        },
        "papermill": {
          "duration": 5.883186,
          "end_time": "2025-12-02T20:11:20.751728",
          "exception": false,
          "start_time": "2025-12-02T20:11:14.868542",
          "status": "completed"
        },
        "tags": [],
        "id": "161f407f"
      },
      "outputs": [],
      "source": [
        "# Cell 2: Imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch_sparse import SparseTensor, matmul\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tqdm.auto import tqdm\n",
        "import scipy.sparse as sp\n",
        "import math\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import time\n",
        "import os\n",
        "\n",
        "# Enable CUDA optimizations\n",
        "torch.backends.cudnn.benchmark = True\n",
        "torch.backends.cuda.matmul.allow_tf32 = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b88ec45",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-02T20:11:20.762460Z",
          "iopub.status.busy": "2025-12-02T20:11:20.761631Z",
          "iopub.status.idle": "2025-12-02T20:11:20.768919Z",
          "shell.execute_reply": "2025-12-02T20:11:20.768216Z"
        },
        "papermill": {
          "duration": 0.014699,
          "end_time": "2025-12-02T20:11:20.770219",
          "exception": false,
          "start_time": "2025-12-02T20:11:20.755520",
          "status": "completed"
        },
        "tags": [],
        "id": "2b88ec45"
      },
      "outputs": [],
      "source": [
        "# Cell 3: Data Loader\n",
        "class PreprocessedDataLoader:\n",
        "    def __init__(self, data_dir='/kaggle/input/dkr2025/'):\n",
        "        self.data_dir = data_dir\n",
        "\n",
        "    def load_preprocessed_data(self):\n",
        "        \"\"\"Load preprocessed data\"\"\"\n",
        "        print(\"Loading preprocessed data...\")\n",
        "\n",
        "        # Load sparse matrices\n",
        "        train_matrix = sp.load_npz(self.data_dir + 'train_matrix.npz')\n",
        "        test_matrix = sp.load_npz(self.data_dir + 'test_matrix.npz')\n",
        "        adj_matrix = sp.load_npz(self.data_dir + 'adj_matrix.npz')\n",
        "\n",
        "        # Load mappings\n",
        "        user_to_idx = np.load(self.data_dir + 'user_to_idx.npy', allow_pickle=True).item()\n",
        "        movie_to_idx = np.load(self.data_dir + 'movie_to_idx.npy', allow_pickle=True).item()\n",
        "\n",
        "        # Load DataFrame with ratings\n",
        "        train_ratings = pd.read_csv(self.data_dir + 'train_ratings.csv')\n",
        "        test_ratings = pd.read_csv(self.data_dir + 'test_ratings.csv')\n",
        "\n",
        "        print(\"Data successfully loaded!\")\n",
        "        print(f\"Users: {len(user_to_idx):,}\")\n",
        "        print(f\"Movies: {len(movie_to_idx):,}\")\n",
        "        print(f\"Training interactions: {len(train_ratings):,}\")\n",
        "        print(f\"Test interactions: {len(test_ratings):,}\")\n",
        "\n",
        "        return {\n",
        "            'train_matrix': train_matrix,\n",
        "            'test_matrix': test_matrix,\n",
        "            'adj_matrix': adj_matrix,\n",
        "            'user_to_idx': user_to_idx,\n",
        "            'movie_to_idx': movie_to_idx,\n",
        "            'train_ratings': train_ratings,\n",
        "            'test_ratings': test_ratings\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d031727",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-02T20:11:20.778064Z",
          "iopub.status.busy": "2025-12-02T20:11:20.777820Z",
          "iopub.status.idle": "2025-12-02T20:11:20.788005Z",
          "shell.execute_reply": "2025-12-02T20:11:20.787211Z"
        },
        "papermill": {
          "duration": 0.015748,
          "end_time": "2025-12-02T20:11:20.789365",
          "exception": false,
          "start_time": "2025-12-02T20:11:20.773617",
          "status": "completed"
        },
        "tags": [],
        "id": "2d031727"
      },
      "outputs": [],
      "source": [
        "# Cell 4: Dataset with 1 negative example\n",
        "class MovieLensDataset(Dataset):\n",
        "    def __init__(self, ratings_df, num_users, num_movies):\n",
        "        \"\"\"Dataset for LightGCN training with 1 negative example\"\"\"\n",
        "        # Take only positive interactions (label=1)\n",
        "        positive_ratings = ratings_df[ratings_df['label'] == 1].copy()\n",
        "\n",
        "        # Create interaction set for quick checking\n",
        "        interactions_set = set(zip(positive_ratings['user_idx'], positive_ratings['movie_idx']))\n",
        "\n",
        "        self.users = positive_ratings['user_idx'].values\n",
        "        self.items = positive_ratings['movie_idx'].values\n",
        "        self.num_users = num_users\n",
        "        self.num_movies = num_movies\n",
        "        self.interactions_set = interactions_set\n",
        "\n",
        "        # Prepare popular movies for better negative sampling\n",
        "        item_counts = positive_ratings['movie_idx'].value_counts()\n",
        "        self.popular_items = item_counts.index.values[:10000]  # 10k popular movies\n",
        "\n",
        "        print(f\"Positive interactions: {len(self.users):,}\")\n",
        "        print(f\"Using 1 negative example per positive\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.users)\n",
        "\n",
        "    def sample_negative_item(self, user, pos_item):\n",
        "        \"\"\"Sample one negative item\"\"\"\n",
        "        attempts = 0\n",
        "        while attempts < 100:\n",
        "            # Sample from popular movies with 70% probability\n",
        "            if np.random.random() < 0.7 and len(self.popular_items) > 0:\n",
        "                neg_item = np.random.choice(self.popular_items)\n",
        "            else:\n",
        "                neg_item = np.random.randint(0, self.num_movies)\n",
        "\n",
        "            # Verify this is truly a negative interaction\n",
        "            if neg_item != pos_item and (user, neg_item) not in self.interactions_set:\n",
        "                return neg_item\n",
        "            attempts += 1\n",
        "\n",
        "        # If not found, return random (not equal to positive)\n",
        "        neg_item = np.random.randint(0, self.num_movies)\n",
        "        while neg_item == pos_item:\n",
        "            neg_item = np.random.randint(0, self.num_movies)\n",
        "        return neg_item\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        user = self.users[idx]\n",
        "        pos_item = self.items[idx]\n",
        "\n",
        "        # Sample ONE negative item\n",
        "        neg_item = self.sample_negative_item(user, pos_item)\n",
        "\n",
        "        return {\n",
        "            'user': torch.tensor(user, dtype=torch.long),\n",
        "            'pos_item': torch.tensor(pos_item, dtype=torch.long),\n",
        "            'neg_item': torch.tensor(neg_item, dtype=torch.long)  # Only 1!\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52a2988d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-02T20:11:20.797499Z",
          "iopub.status.busy": "2025-12-02T20:11:20.796704Z",
          "iopub.status.idle": "2025-12-02T20:11:20.803474Z",
          "shell.execute_reply": "2025-12-02T20:11:20.802860Z"
        },
        "papermill": {
          "duration": 0.011881,
          "end_time": "2025-12-02T20:11:20.804642",
          "exception": false,
          "start_time": "2025-12-02T20:11:20.792761",
          "status": "completed"
        },
        "tags": [],
        "id": "52a2988d"
      },
      "outputs": [],
      "source": [
        "# Cell 5: LightGCN model (fixed according to recommendations)\n",
        "class LightGCN(nn.Module):\n",
        "    def __init__(self, num_users, num_items, embedding_dim=64, num_layers=3):\n",
        "        super().__init__()\n",
        "        self.num_users = num_users\n",
        "        self.num_items = num_items\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # User and item embeddings\n",
        "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
        "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
        "\n",
        "        # Initialization as in original LightGCN\n",
        "        nn.init.normal_(self.user_embedding.weight, std=0.1)\n",
        "        nn.init.normal_(self.item_embedding.weight, std=0.1)\n",
        "\n",
        "        # NOT using layer weights (simple average in original)\n",
        "\n",
        "    def forward(self, adjacency_matrix):\n",
        "        # Initial embeddings\n",
        "        user_emb = self.user_embedding.weight\n",
        "        item_emb = self.item_embedding.weight\n",
        "\n",
        "        # Concatenate for graph propagation\n",
        "        all_embeddings = torch.cat([user_emb, item_emb], dim=0)\n",
        "        embeddings_per_layer = [all_embeddings]\n",
        "\n",
        "        # Propagation through layers (LightGCN propagation)\n",
        "        for _ in range(self.num_layers):\n",
        "            all_embeddings = matmul(adjacency_matrix, all_embeddings)\n",
        "            embeddings_per_layer.append(all_embeddings)\n",
        "\n",
        "        # Weighted sum of all layer embeddings (simple average)\n",
        "        final_embeddings = torch.stack(embeddings_per_layer, dim=0).mean(dim=0)\n",
        "\n",
        "        # Split back into users and items\n",
        "        final_user_emb, final_item_emb = torch.split(\n",
        "            final_embeddings, [self.num_users, self.num_items]\n",
        "        )\n",
        "\n",
        "        return final_user_emb, final_item_emb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8c9a24f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-02T20:11:20.812147Z",
          "iopub.status.busy": "2025-12-02T20:11:20.811874Z",
          "iopub.status.idle": "2025-12-02T20:11:20.816850Z",
          "shell.execute_reply": "2025-12-02T20:11:20.816029Z"
        },
        "papermill": {
          "duration": 0.010187,
          "end_time": "2025-12-02T20:11:20.818106",
          "exception": false,
          "start_time": "2025-12-02T20:11:20.807919",
          "status": "completed"
        },
        "tags": [],
        "id": "d8c9a24f"
      },
      "outputs": [],
      "source": [
        "# Cell 6: BPRLoss WITHOUT regularization\n",
        "class BPRLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # NO lambda_reg! LightGCN doesn't use embedding regularization\n",
        "\n",
        "    def forward(self, user_emb, pos_item_emb, neg_item_emb):\n",
        "        \"\"\"Pure BPR Loss as in original LightGCN\"\"\"\n",
        "        # Calculate scores\n",
        "        pos_scores = (user_emb * pos_item_emb).sum(dim=1)\n",
        "        neg_scores = (user_emb * neg_item_emb).sum(dim=1)\n",
        "\n",
        "        # BPR loss without regularization\n",
        "        loss = -torch.log(torch.sigmoid(pos_scores - neg_scores) + 1e-8).mean()\n",
        "\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80b68a70",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-02T20:11:20.826212Z",
          "iopub.status.busy": "2025-12-02T20:11:20.825923Z",
          "iopub.status.idle": "2025-12-02T20:11:20.842921Z",
          "shell.execute_reply": "2025-12-02T20:11:20.842074Z"
        },
        "papermill": {
          "duration": 0.022762,
          "end_time": "2025-12-02T20:11:20.844286",
          "exception": false,
          "start_time": "2025-12-02T20:11:20.821524",
          "status": "completed"
        },
        "tags": [],
        "id": "80b68a70"
      },
      "outputs": [],
      "source": [
        "# Cell 7: Metrics Calculator with Precision@K and Recall@K\n",
        "class MetricsCalculator:\n",
        "    def __init__(self, train_matrix, test_matrix, num_users, num_items, device, k=10):\n",
        "        self.train_matrix = train_matrix.tolil()\n",
        "        self.test_matrix = test_matrix.tolil()\n",
        "        self.num_users = num_users\n",
        "        self.num_items = num_items\n",
        "        self.device = device\n",
        "        self.k = k\n",
        "\n",
        "        # Cache training items for quick access\n",
        "        self.train_items = {}\n",
        "        for user in range(num_users):\n",
        "            self.train_items[user] = set(self.train_matrix.rows[user])\n",
        "\n",
        "    def calculate_all_metrics(self, model, adjacency_matrix, batch_size=4096, roc_samples=10000):\n",
        "        \"\"\"Calculate all metrics: HR@K, NDCG@K, Precision@K, Recall@K, ROC-AUC\"\"\"\n",
        "        model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            user_emb, item_emb = model(adjacency_matrix)\n",
        "\n",
        "        # Get users with test interactions\n",
        "        users_with_test = [\n",
        "            u for u in range(self.num_users)\n",
        "            if len(self.test_matrix.rows[u]) > 0\n",
        "        ]\n",
        "\n",
        "        print(f\"Calculating metrics for {len(users_with_test)} users...\")\n",
        "\n",
        "        hr_list, ndcg_list, precision_list, recall_list = [], [], [], []\n",
        "\n",
        "        # Batch processing for HR, NDCG, Precision, Recall\n",
        "        for start_idx in tqdm(range(0, len(users_with_test), batch_size),\n",
        "                             desc=\"Calculating ranking metrics\"):\n",
        "            end_idx = min(start_idx + batch_size, len(users_with_test))\n",
        "            batch_users = users_with_test[start_idx:end_idx]\n",
        "\n",
        "            if not batch_users:\n",
        "                continue\n",
        "\n",
        "            # User embeddings for batch\n",
        "            batch_user_emb = user_emb[batch_users]\n",
        "\n",
        "            # Scores for all items\n",
        "            scores = torch.matmul(batch_user_emb, item_emb.T)\n",
        "\n",
        "            # Mask training items\n",
        "            for i, user in enumerate(batch_users):\n",
        "                train_indices = list(self.train_items[user])\n",
        "                if train_indices:\n",
        "                    scores[i, train_indices] = -float('inf')\n",
        "\n",
        "            # Get top-K predictions\n",
        "            _, topk_indices = torch.topk(scores, k=self.k, dim=1)\n",
        "\n",
        "            # Calculate metrics for each user in batch\n",
        "            for i, user in enumerate(batch_users):\n",
        "                test_items = self.test_matrix.rows[user]\n",
        "                if not test_items:\n",
        "                    continue\n",
        "\n",
        "                # Take all test items as relevant\n",
        "                relevant_items = set(test_items)\n",
        "                predicted_items = set(topk_indices[i].cpu().numpy())\n",
        "\n",
        "                # Hit Rate\n",
        "                hr = 1 if predicted_items.intersection(relevant_items) else 0\n",
        "                hr_list.append(hr)\n",
        "\n",
        "                # NDCG\n",
        "                dcg = 0.0\n",
        "                for rank, item in enumerate(topk_indices[i].cpu().numpy(), 1):\n",
        "                    if item in relevant_items:\n",
        "                        dcg += 1 / math.log2(rank + 1)\n",
        "\n",
        "                # Ideal DCG (IDCG)\n",
        "                idcg = sum(1 / math.log2(r + 1) for r in range(1, min(len(relevant_items), self.k) + 1))\n",
        "                ndcg = dcg / idcg if idcg > 0 else 0\n",
        "                ndcg_list.append(ndcg)\n",
        "\n",
        "                # Precision@K\n",
        "                hits = len(predicted_items.intersection(relevant_items))\n",
        "                precision = hits / self.k\n",
        "                precision_list.append(precision)\n",
        "\n",
        "                # Recall@K\n",
        "                recall = hits / len(relevant_items) if len(relevant_items) > 0 else 0\n",
        "                recall_list.append(recall)\n",
        "\n",
        "        # Calculate ROC-AUC\n",
        "        roc_auc = self._calculate_roc_auc(user_emb, item_emb, num_samples=roc_samples)\n",
        "\n",
        "        # Average metrics\n",
        "        metrics = {\n",
        "            f'hr@{self.k}': np.mean(hr_list) if hr_list else 0.0,\n",
        "            f'ndcg@{self.k}': np.mean(ndcg_list) if ndcg_list else 0.0,\n",
        "            f'precision@{self.k}': np.mean(precision_list) if precision_list else 0.0,\n",
        "            f'recall@{self.k}': np.mean(recall_list) if recall_list else 0.0,\n",
        "            'roc_auc': roc_auc\n",
        "        }\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    def _calculate_roc_auc(self, user_emb, item_emb, num_samples=10000):\n",
        "        \"\"\"Calculate ROC-AUC\"\"\"\n",
        "        scores = []\n",
        "        labels = []\n",
        "\n",
        "        # Sample users\n",
        "        users_with_test = [\n",
        "            u for u in range(self.num_users)\n",
        "            if len(self.test_matrix.rows[u]) > 0\n",
        "        ]\n",
        "\n",
        "        num_users_to_sample = min(num_samples // 2, len(users_with_test))\n",
        "        sampled_users = np.random.choice(users_with_test, size=num_users_to_sample, replace=False)\n",
        "\n",
        "        for user in tqdm(sampled_users, desc=\"ROC-AUC\"):\n",
        "            # Positive scores (test items)\n",
        "            test_items = self.test_matrix.rows[user]\n",
        "            if not test_items:\n",
        "                continue\n",
        "\n",
        "            # Take all test items as positive\n",
        "            for pos_item in test_items:\n",
        "                pos_score = torch.dot(user_emb[user], item_emb[pos_item]).item()\n",
        "                scores.append(pos_score)\n",
        "                labels.append(1)\n",
        "\n",
        "            # Negative scores (not in train and not in test)\n",
        "            train_items = self.train_items[user]\n",
        "            test_set = set(test_items)\n",
        "            forbidden = train_items.union(test_set)\n",
        "\n",
        "            # Find negative items\n",
        "            attempts = 0\n",
        "            neg_samples_needed = len(test_items)  # Balance positive and negative\n",
        "            while attempts < 100 and len(scores) < labels.count(1) + neg_samples_needed:\n",
        "                neg_item = np.random.randint(0, self.num_items)\n",
        "                if neg_item not in forbidden:\n",
        "                    neg_score = torch.dot(user_emb[user], item_emb[neg_item]).item()\n",
        "                    scores.append(neg_score)\n",
        "                    labels.append(0)\n",
        "                attempts += 1\n",
        "\n",
        "        try:\n",
        "            roc_auc = roc_auc_score(labels, scores)\n",
        "        except:\n",
        "            roc_auc = 0.5\n",
        "\n",
        "        return roc_auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc8f7f9a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-02T20:11:20.852820Z",
          "iopub.status.busy": "2025-12-02T20:11:20.852518Z",
          "iopub.status.idle": "2025-12-02T20:11:20.866334Z",
          "shell.execute_reply": "2025-12-02T20:11:20.865512Z"
        },
        "papermill": {
          "duration": 0.01983,
          "end_time": "2025-12-02T20:11:20.867644",
          "exception": false,
          "start_time": "2025-12-02T20:11:20.847814",
          "status": "completed"
        },
        "tags": [],
        "id": "fc8f7f9a"
      },
      "outputs": [],
      "source": [
        "# Cell 8: Trainer with early stopping\n",
        "class Trainer:\n",
        "    def __init__(self, model, train_loader, config, metrics_calculator):\n",
        "        self.model = model\n",
        "        self.train_loader = train_loader\n",
        "        self.config = config\n",
        "        self.metrics_calculator = metrics_calculator\n",
        "        self.device = next(model.parameters()).device\n",
        "\n",
        "        # Optimizer WITHOUT weight_decay on embeddings\n",
        "        self.optimizer = torch.optim.Adam(\n",
        "            model.parameters(),\n",
        "            lr=config['learning_rate']\n",
        "            # NO weight_decay! LightGCN doesn't use L2 regularization\n",
        "        )\n",
        "\n",
        "        self.criterion = BPRLoss()  # Without regularization\n",
        "\n",
        "        # For early stopping\n",
        "        self.best_hr = 0\n",
        "        self.patience_counter = 0\n",
        "        self.best_epoch = 0\n",
        "\n",
        "        self.train_losses = []\n",
        "        self.val_metrics_history = []\n",
        "\n",
        "    def train_epoch(self, adjacency_matrix):\n",
        "        \"\"\"One training epoch\"\"\"\n",
        "        self.model.train()\n",
        "        total_loss = 0\n",
        "        num_batches = 0\n",
        "\n",
        "        progress_bar = tqdm(self.train_loader, desc=\"Training\")\n",
        "\n",
        "        for batch in progress_bar:\n",
        "            users = batch['user'].to(self.device)\n",
        "            pos_items = batch['pos_item'].to(self.device)\n",
        "            neg_items = batch['neg_item'].to(self.device)  # Only 1 negative!\n",
        "\n",
        "            # Get embeddings\n",
        "            user_emb, item_emb = self.model(adjacency_matrix)\n",
        "\n",
        "            # Embeddings for batch\n",
        "            batch_user_emb = user_emb[users]\n",
        "            batch_pos_emb = item_emb[pos_items]\n",
        "            batch_neg_emb = item_emb[neg_items]\n",
        "\n",
        "            # BPR loss with 1 negative example\n",
        "            loss = self.criterion(batch_user_emb, batch_pos_emb, batch_neg_emb)\n",
        "\n",
        "            # Optimization\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "\n",
        "            # Gradient clipping for stability\n",
        "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
        "\n",
        "            self.optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            num_batches += 1\n",
        "\n",
        "            progress_bar.set_postfix({\n",
        "                'loss': f'{loss.item():.4f}',\n",
        "                'avg_loss': f'{total_loss/num_batches:.4f}'\n",
        "            })\n",
        "\n",
        "        return total_loss / num_batches\n",
        "\n",
        "    def validate(self, adjacency_matrix, epoch):\n",
        "        \"\"\"Validate the model\"\"\"\n",
        "        print(\"\\nValidation...\")\n",
        "\n",
        "        # Calculate all metrics\n",
        "        metrics = self.metrics_calculator.calculate_all_metrics(\n",
        "            self.model, adjacency_matrix, batch_size=4096\n",
        "        )\n",
        "\n",
        "        hr = metrics[f'hr@{self.metrics_calculator.k}']\n",
        "\n",
        "        print(f\"  Epoch {epoch}:\")\n",
        "        for metric_name, metric_value in metrics.items():\n",
        "            print(f\"  {metric_name}: {metric_value:.4f}\")\n",
        "\n",
        "        # Early stopping\n",
        "        if hr > self.best_hr:\n",
        "            self.best_hr = hr\n",
        "            self.best_epoch = epoch\n",
        "            self.patience_counter = 0\n",
        "\n",
        "            # Save best model\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': self.model.state_dict(),\n",
        "                'hr': hr,\n",
        "                'ndcg': metrics[f'ndcg@{self.metrics_calculator.k}'],\n",
        "                'precision': metrics[f'precision@{self.metrics_calculator.k}'],\n",
        "                'recall': metrics[f'recall@{self.metrics_calculator.k}'],\n",
        "                'roc_auc': metrics['roc_auc']\n",
        "            }, 'best_model.pth')\n",
        "\n",
        "            print(f\"  Saved best model! HR@{self.metrics_calculator.k}: {hr:.4f}\")\n",
        "        else:\n",
        "            self.patience_counter += 1\n",
        "            print(f\"  Patience: {self.patience_counter}/{self.config['patience']}\")\n",
        "\n",
        "        metrics['epoch'] = epoch\n",
        "        self.val_metrics_history.append(metrics)\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    def train(self, adjacency_matrix, epochs):\n",
        "        \"\"\"Full training cycle with early stopping\"\"\"\n",
        "        print(f\"Starting training for {epochs} epochs\")\n",
        "        print(f\"Early stopping after {self.config['patience']} epochs without improvement\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        for epoch in range(1, epochs + 1):\n",
        "            print(f\"\\nEpoch {epoch}/{epochs}\")\n",
        "            print(\"-\" * 50)\n",
        "\n",
        "            # Training\n",
        "            train_loss = self.train_epoch(adjacency_matrix)\n",
        "            self.train_losses.append(train_loss)\n",
        "\n",
        "            # Validation\n",
        "            val_metrics = self.validate(adjacency_matrix, epoch)\n",
        "\n",
        "            # Check early stopping\n",
        "            if self.patience_counter >= self.config['patience']:\n",
        "                print(f\"\\nEarly stopping at epoch {epoch}\")\n",
        "                print(f\"Best HR@{self.metrics_calculator.k}: {self.best_hr:.4f} (epoch {self.best_epoch})\")\n",
        "                break\n",
        "\n",
        "            # Print statistics\n",
        "            epoch_time = time.time() - start_time\n",
        "            print(f\"Epoch time: {epoch_time:.1f} sec\")\n",
        "            print(f\"Best HR@{self.metrics_calculator.k}: {self.best_hr:.4f}\")\n",
        "\n",
        "        total_time = time.time() - start_time\n",
        "        print(f\"\\nTraining completed in {total_time:.1f} sec\")\n",
        "        print(f\"Total epochs: {epoch}\")\n",
        "        print(f\"Final best HR@{self.metrics_calculator.k}: {self.best_hr:.4f} (epoch {self.best_epoch})\")\n",
        "\n",
        "        return self.best_hr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0312631",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-02T20:11:20.876447Z",
          "iopub.status.busy": "2025-12-02T20:11:20.876076Z",
          "iopub.status.idle": "2025-12-02T23:18:28.980688Z",
          "shell.execute_reply": "2025-12-02T23:18:28.979918Z"
        },
        "papermill": {
          "duration": 11228.115231,
          "end_time": "2025-12-02T23:18:28.986634",
          "exception": false,
          "start_time": "2025-12-02T20:11:20.871403",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "fadd1b078ca2435bbb9c39379800a6d8",
            "e28fd099a6a34d27a7c8064f667ea109",
            "fc1a728829c24a4e8f4e490683064fbd",
            "66c7ae799b3241ecb9697bcc2faa88d3",
            "077cf2bad4c34828addd2feee2831895",
            "1815fb75715840868305c36847d76372",
            "2be5ef9ecf6f44db8565f11189545123",
            "8732af4f56fe4040889ee8e7d0cb3717",
            "48191700e9d34180a454235659f95079",
            "b2b30790f8c5438aa5c6fd045425602b",
            "4ada9f504282426a98aea0061070dc9e",
            "596b062c698b44ad9e8458e175946cb6",
            "c8790126bc50467f8cb5424b62e15517",
            "50d69e846aad4c3f9b2602fed54ce5ea",
            "a7cb967ffbb540b28828327454879f31",
            "1060bafccad843a1977d9886ff23ee33",
            "353fab5bd15e420e96693ca6c89ce609"
          ]
        },
        "id": "e0312631",
        "outputId": "5796b1d1-588d-44de-9b35-3399fe83199c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LightGCN Configuration:\n",
            "  embedding_dim: 64\n",
            "  num_layers: 3\n",
            "  learning_rate: 0.001\n",
            "  weight_decay: 0.0\n",
            "  batch_size: 2048\n",
            "  epochs: 5\n",
            "  patience: 20\n",
            "  k: 50\n",
            "\n",
            "1. Loading data...\n",
            "Loading preprocessed data...\n",
            "Data successfully loaded!\n",
            "Users: 162,541\n",
            "Movies: 59,047\n",
            "Training interactions: 20,000,076\n",
            "Test interactions: 610,664\n",
            "\n",
            "2. Preparing graph...\n",
            "\n",
            "3. Preparing training data...\n",
            "Positive interactions: 12,306,450\n",
            "Using 1 negative example per positive\n",
            "\n",
            "4. Creating LightGCN model...\n",
            "Device: cuda\n",
            "Model parameters: 14,181,632\n",
            "\n",
            "5. Training model...\n",
            "Starting training for 5 epochs\n",
            "Early stopping after 20 epochs without improvement\n",
            "\n",
            "Epoch 1/5\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fadd1b078ca2435bbb9c39379800a6d8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training:   0%|          | 0/6010 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Validation...\n",
            "Calculating metrics for 6342 users...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e28fd099a6a34d27a7c8064f667ea109",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Calculating ranking metrics:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fc1a728829c24a4e8f4e490683064fbd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "ROC-AUC:   0%|          | 0/5000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Epoch 1:\n",
            "  hr@50: 0.7874\n",
            "  ndcg@50: 0.1744\n",
            "  precision@50: 0.1331\n",
            "  recall@50: 0.1177\n",
            "  roc_auc: 0.9322\n",
            "  Saved best model! HR@50: 0.7874\n",
            "Epoch time: 2241.8 sec\n",
            "Best HR@50: 0.7874\n",
            "\n",
            "Epoch 2/5\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "66c7ae799b3241ecb9697bcc2faa88d3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training:   0%|          | 0/6010 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Validation...\n",
            "Calculating metrics for 6342 users...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "077cf2bad4c34828addd2feee2831895",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Calculating ranking metrics:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1815fb75715840868305c36847d76372",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "ROC-AUC:   0%|          | 0/5000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Epoch 2:\n",
            "  hr@50: 0.7960\n",
            "  ndcg@50: 0.1826\n",
            "  precision@50: 0.1386\n",
            "  recall@50: 0.1229\n",
            "  roc_auc: 0.9314\n",
            "  Saved best model! HR@50: 0.7960\n",
            "Epoch time: 4467.8 sec\n",
            "Best HR@50: 0.7960\n",
            "\n",
            "Epoch 3/5\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2be5ef9ecf6f44db8565f11189545123",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training:   0%|          | 0/6010 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Validation...\n",
            "Calculating metrics for 6342 users...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8732af4f56fe4040889ee8e7d0cb3717",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Calculating ranking metrics:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "48191700e9d34180a454235659f95079",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "ROC-AUC:   0%|          | 0/5000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Epoch 3:\n",
            "  hr@50: 0.8007\n",
            "  ndcg@50: 0.1847\n",
            "  precision@50: 0.1400\n",
            "  recall@50: 0.1253\n",
            "  roc_auc: 0.9370\n",
            "  Saved best model! HR@50: 0.8007\n",
            "Epoch time: 6677.5 sec\n",
            "Best HR@50: 0.8007\n",
            "\n",
            "Epoch 4/5\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b2b30790f8c5438aa5c6fd045425602b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training:   0%|          | 0/6010 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Validation...\n",
            "Calculating metrics for 6342 users...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4ada9f504282426a98aea0061070dc9e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Calculating ranking metrics:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "596b062c698b44ad9e8458e175946cb6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "ROC-AUC:   0%|          | 0/5000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Epoch 4:\n",
            "  hr@50: 0.8083\n",
            "  ndcg@50: 0.1898\n",
            "  precision@50: 0.1438\n",
            "  recall@50: 0.1289\n",
            "  roc_auc: 0.9393\n",
            "  Saved best model! HR@50: 0.8083\n",
            "Epoch time: 8898.5 sec\n",
            "Best HR@50: 0.8083\n",
            "\n",
            "Epoch 5/5\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c8790126bc50467f8cb5424b62e15517",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training:   0%|          | 0/6010 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Validation...\n",
            "Calculating metrics for 6342 users...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "50d69e846aad4c3f9b2602fed54ce5ea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Calculating ranking metrics:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a7cb967ffbb540b28828327454879f31",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "ROC-AUC:   0%|          | 0/5000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Epoch 5:\n",
            "  hr@50: 0.8147\n",
            "  ndcg@50: 0.1942\n",
            "  precision@50: 0.1469\n",
            "  recall@50: 0.1316\n",
            "  roc_auc: 0.9389\n",
            "  Saved best model! HR@50: 0.8147\n",
            "Epoch time: 11124.7 sec\n",
            "Best HR@50: 0.8147\n",
            "\n",
            "Training completed in 11124.7 sec\n",
            "Total epochs: 5\n",
            "Final best HR@50: 0.8147 (epoch 5)\n",
            "\n",
            "6. Final testing...\n",
            "Loaded best model from epoch 5\n",
            "Best metrics:\n",
            "  HR@50: 0.8147\n",
            "  NDCG@50: 0.1942\n",
            "  Precision@50: 0.1469\n",
            "  Recall@50: 0.1316\n",
            "  ROC-AUC: 0.9389\n",
            "Calculating metrics for 6342 users...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1060bafccad843a1977d9886ff23ee33",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Calculating ranking metrics:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "353fab5bd15e420e96693ca6c89ce609",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "ROC-AUC:   0%|          | 0/5000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "FINAL RESULTS:\n",
            "============================================================\n",
            "hr@50                0.8147\n",
            "ndcg@50              0.1942\n",
            "precision@50         0.1469\n",
            "recall@50            0.1316\n",
            "roc_auc              0.9462\n",
            "Best HR during training: 0.8147\n",
            "============================================================\n",
            "\n",
            "Training history saved to training_history.csv\n"
          ]
        }
      ],
      "source": [
        "# Cell 9: Main function\n",
        "def main():\n",
        "    # CONFIGURATION according to LightGCN recommendations\n",
        "    config = {\n",
        "        'embedding_dim': 64,          # LightGCN standard: 64 (not more!)\n",
        "        'num_layers': 3,              # 2-4 layers optimal\n",
        "        'learning_rate': 1e-3,        # Standard learning rate\n",
        "        'weight_decay': 0.0,          # IMPORTANT: LightGCN does NOT use L2 regularization!\n",
        "        'batch_size': 2048,           # Optimal batch size\n",
        "        'epochs': 5,                # LightGCN trains slowly (hundreds of epochs)\n",
        "        'patience': 20,               # Early stopping\n",
        "        'k': 50                       # For @K metrics\n",
        "    }\n",
        "\n",
        "    print(\"LightGCN Configuration:\")\n",
        "    for key, value in config.items():\n",
        "        print(f\"  {key}: {value}\")\n",
        "\n",
        "    # 1. Load data\n",
        "    print(\"\\n1. Loading data...\")\n",
        "    data_loader = PreprocessedDataLoader('/kaggle/input/dkr2025/')\n",
        "    data = data_loader.load_preprocessed_data()\n",
        "\n",
        "    num_users = len(data['user_to_idx'])\n",
        "    num_movies = len(data['movie_to_idx'])\n",
        "\n",
        "    # 2. Prepare normalized adjacency matrix for LightGCN\n",
        "    print(\"\\n2. Preparing graph...\")\n",
        "    adj_matrix = data['adj_matrix']\n",
        "\n",
        "    # Normalization as in original LightGCN\n",
        "    adj_matrix = adj_matrix.tolil()\n",
        "    adj_matrix = adj_matrix + sp.eye(adj_matrix.shape[0])  # Add self-loop\n",
        "\n",
        "    rowsum = np.array(adj_matrix.sum(1)).flatten()\n",
        "    d_inv_sqrt = np.power(rowsum, -0.5)\n",
        "    d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n",
        "    d_mat_inv_sqrt = sp.diags(d_inv_sqrt)\n",
        "\n",
        "    norm_adj = d_mat_inv_sqrt.dot(adj_matrix).dot(d_mat_inv_sqrt)\n",
        "    norm_adj_coo = norm_adj.tocoo()\n",
        "\n",
        "    # Create SparseTensor\n",
        "    adjacency_matrix = SparseTensor(\n",
        "        row=torch.tensor(norm_adj_coo.row, dtype=torch.long),\n",
        "        col=torch.tensor(norm_adj_coo.col, dtype=torch.long),\n",
        "        value=torch.tensor(norm_adj_coo.data, dtype=torch.float32),\n",
        "        sparse_sizes=(norm_adj_coo.shape[0], norm_adj_coo.shape[1])\n",
        "    )\n",
        "\n",
        "    # 3. Create datasets and loaders\n",
        "    print(\"\\n3. Preparing training data...\")\n",
        "    train_dataset = MovieLensDataset(\n",
        "        data['train_ratings'],\n",
        "        num_users,\n",
        "        num_movies  # Only 1 negative by default\n",
        "    )\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=config['batch_size'],\n",
        "        shuffle=True,\n",
        "        num_workers=0,  # Avoid multiprocessing issues\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    # 4. Create model\n",
        "    print(\"\\n4. Creating LightGCN model...\")\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Device: {device}\")\n",
        "\n",
        "    model = LightGCN(\n",
        "        num_users=num_users,\n",
        "        num_items=num_movies,\n",
        "        embedding_dim=config['embedding_dim'],\n",
        "        num_layers=config['num_layers']\n",
        "    ).to(device)\n",
        "\n",
        "    adjacency_matrix = adjacency_matrix.to(device)\n",
        "\n",
        "    print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "\n",
        "    # 5. Create metrics calculator\n",
        "    metrics_calculator = MetricsCalculator(\n",
        "        train_matrix=data['train_matrix'],\n",
        "        test_matrix=data['test_matrix'],\n",
        "        num_users=num_users,\n",
        "        num_items=num_movies,\n",
        "        device=device,\n",
        "        k=config['k']\n",
        "    )\n",
        "\n",
        "    # 6. Training\n",
        "    print(\"\\n5. Training model...\")\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        train_loader=train_loader,\n",
        "        config=config,\n",
        "        metrics_calculator=metrics_calculator\n",
        "    )\n",
        "\n",
        "    best_hr = trainer.train(adjacency_matrix, config['epochs'])\n",
        "\n",
        "    # 7. Final testing\n",
        "    print(\"\\n6. Final testing...\")\n",
        "    if os.path.exists('best_model.pth'):\n",
        "        # Fix loading error\n",
        "        try:\n",
        "            checkpoint = torch.load('best_model.pth', weights_only=False)\n",
        "        except:\n",
        "            # Alternative way\n",
        "            checkpoint = torch.load('best_model.pth', weights_only=False, map_location=device)\n",
        "\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        print(f\"Loaded best model from epoch {checkpoint['epoch']}\")\n",
        "        print(f\"Best metrics:\")\n",
        "        print(f\"  HR@{config['k']}: {checkpoint['hr']:.4f}\")\n",
        "        print(f\"  NDCG@{config['k']}: {checkpoint['ndcg']:.4f}\")\n",
        "        print(f\"  Precision@{config['k']}: {checkpoint['precision']:.4f}\")\n",
        "        print(f\"  Recall@{config['k']}: {checkpoint['recall']:.4f}\")\n",
        "        print(f\"  ROC-AUC: {checkpoint['roc_auc']:.4f}\")\n",
        "\n",
        "    # Final metrics\n",
        "    final_metrics = metrics_calculator.calculate_all_metrics(\n",
        "        model, adjacency_matrix, batch_size=4096\n",
        "    )\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"FINAL RESULTS:\")\n",
        "    print(\"=\"*60)\n",
        "    for metric_name, metric_value in final_metrics.items():\n",
        "        print(f\"{metric_name:20} {metric_value:.4f}\")\n",
        "    print(f\"{'Best HR during training:':20} {best_hr:.4f}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Save metrics history\n",
        "    history_df = pd.DataFrame(trainer.val_metrics_history)\n",
        "    history_df.to_csv('training_history.csv', index=False)\n",
        "    print(\"\\nTraining history saved to training_history.csv\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31fe8b39",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-02T23:18:28.999766Z",
          "iopub.status.busy": "2025-12-02T23:18:28.999502Z",
          "iopub.status.idle": "2025-12-02T23:18:29.008788Z",
          "shell.execute_reply": "2025-12-02T23:18:29.008205Z"
        },
        "papermill": {
          "duration": 0.017016,
          "end_time": "2025-12-02T23:18:29.009893",
          "exception": false,
          "start_time": "2025-12-02T23:18:28.992877",
          "status": "completed"
        },
        "tags": [],
        "id": "31fe8b39"
      },
      "outputs": [],
      "source": [
        "# Cell 10: Quick test\n",
        "def quick_test():\n",
        "    \"\"\"Quick test of one batch\"\"\"\n",
        "    print(\"=\"*60)\n",
        "    print(\"QUICK MODEL TEST\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Load minimal data for test\n",
        "    data_loader = PreprocessedDataLoader('/kaggle/input/dkr2025/')\n",
        "    data = data_loader.load_preprocessed_data()\n",
        "\n",
        "    num_users = len(data['user_to_idx'])\n",
        "    num_movies = len(data['movie_to_idx'])\n",
        "\n",
        "    # Create mini-dataset\n",
        "    test_df = data['train_ratings'].head(1000)\n",
        "    test_dataset = MovieLensDataset(test_df, num_users, num_movies)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "    # Create model\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = LightGCN(num_users, num_movies, embedding_dim=64, num_layers=3).to(device)\n",
        "\n",
        "    # Test one batch\n",
        "    batch = next(iter(test_loader))\n",
        "\n",
        "    print(f\"Batch size: {len(batch['user'])}\")\n",
        "    print(f\"Users: {batch['user'][:5].tolist()}\")\n",
        "    print(f\"Pos items: {batch['pos_item'][:5].tolist()}\")\n",
        "    print(f\"Neg items: {batch['neg_item'][:5].tolist()}\")\n",
        "\n",
        "    # Forward pass\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Prepare adjacency matrix\n",
        "        adj_matrix = data['adj_matrix'].tocoo()\n",
        "        adjacency_matrix = SparseTensor(\n",
        "            row=torch.tensor(adj_matrix.row, dtype=torch.long),\n",
        "            col=torch.tensor(adj_matrix.col, dtype=torch.long),\n",
        "            value=torch.tensor(adj_matrix.data, dtype=torch.float32),\n",
        "            sparse_sizes=(adj_matrix.shape[0], adj_matrix.shape[1])\n",
        "        ).to(device)\n",
        "\n",
        "        user_emb, item_emb = model(adjacency_matrix)\n",
        "\n",
        "        users = batch['user'].to(device)\n",
        "        pos_items = batch['pos_item'].to(device)\n",
        "        neg_items = batch['neg_item'].to(device)\n",
        "\n",
        "        # Calculate scores\n",
        "        pos_scores = (user_emb[users] * item_emb[pos_items]).sum(dim=1)\n",
        "        neg_scores = (user_emb[users] * item_emb[neg_items]).sum(dim=1)\n",
        "\n",
        "        print(f\"\\nPositive scores: {pos_scores[:5].cpu().numpy()}\")\n",
        "        print(f\"Negative scores: {neg_scores[:5].cpu().numpy()}\")\n",
        "        print(f\"Mean difference: {pos_scores.mean().item() - neg_scores.mean().item():.4f}\")\n",
        "\n",
        "        # Simple check\n",
        "        if pos_scores.mean() > neg_scores.mean():\n",
        "            print(\"Model correctly distinguishes positive from negative!\")\n",
        "        else:\n",
        "            print(\"Model doesn't distinguish positive and negative examples\")\n",
        "\n",
        "    print(\"\\nTest completed!\")\n",
        "\n",
        "# Run quick test if needed\n",
        "# quick_test()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 11: User Analysis and Recommendations\n",
        "import pandas as pd\n",
        "\n",
        "def load_movie_metadata():\n",
        "    \"\"\"Load movie metadata for title mapping\"\"\"\n",
        "    try:\n",
        "        # Load movies data\n",
        "        movies_df = pd.read_csv(\"/kaggle/input/movie-lens25/movies.csv\")\n",
        "\n",
        "        # Create mapping from movieId to title\n",
        "        movieId_to_title = dict(zip(movies_df[\"movieId\"], movies_df[\"title\"]))\n",
        "\n",
        "        print(f\"Loaded metadata for {len(movieId_to_title)} movies\")\n",
        "        return movieId_to_title\n",
        "    except Exception as e:\n",
        "        print(f\"Could not load movie metadata: {e}\")\n",
        "        return {}\n",
        "\n",
        "def create_reverse_mappings(user_to_idx, movie_to_idx):\n",
        "    \"\"\"Create reverse mappings from internal indices to original IDs\"\"\"\n",
        "    idx_to_user = {v: k for k, v in user_to_idx.items()}\n",
        "    idx_to_movie = {v: k for k, v in movie_to_idx.items()}\n",
        "    return idx_to_user, idx_to_movie\n",
        "\n",
        "def get_top_rated_movies(user_id_internal, ratings_df, idx_to_user, movie_to_idx, movieId_to_title, top_n=10):\n",
        "    \"\"\"Return the user's top-N highest rated movies using ratings.csv.\"\"\"\n",
        "    # Convert internal id → real MovieLens userId\n",
        "    if user_id_internal not in idx_to_user:\n",
        "        print(f\"User ID {user_id_internal} not found in mappings\")\n",
        "        return []\n",
        "\n",
        "    real_user_id = idx_to_user[user_id_internal]\n",
        "\n",
        "    # Get all user ratings\n",
        "    user_ratings = ratings_df[ratings_df[\"userId\"] == real_user_id]\n",
        "\n",
        "    if user_ratings.empty:\n",
        "        print(f\"No ratings found for user {real_user_id}\")\n",
        "        return []\n",
        "\n",
        "    # Sort by rating descending\n",
        "    user_ratings = user_ratings.sort_values(\"rating\", ascending=False)\n",
        "\n",
        "    # Take top N\n",
        "    top = user_ratings.head(top_n)\n",
        "\n",
        "    favorites = []\n",
        "    for _, row in top.iterrows():\n",
        "        movieId = row[\"movieId\"]\n",
        "        rating = row[\"rating\"]\n",
        "        timestamp = row.get(\"timestamp\", None)\n",
        "\n",
        "        # Map movieId → internal item index (if exists)\n",
        "        if movieId in movie_to_idx:\n",
        "            item_idx = movie_to_idx[movieId]\n",
        "            title = movieId_to_title.get(movieId, f\"Unknown {movieId}\")\n",
        "            favorites.append({\n",
        "                'item_idx': item_idx,\n",
        "                'title': title,\n",
        "                'rating': rating,\n",
        "                'timestamp': timestamp\n",
        "            })\n",
        "        else:\n",
        "            # Movie not in our dataset\n",
        "            favorites.append({\n",
        "                'item_idx': None,\n",
        "                'title': movieId_to_title.get(movieId, f\"Unknown {movieId}\"),\n",
        "                'rating': rating,\n",
        "                'timestamp': timestamp\n",
        "            })\n",
        "\n",
        "    return favorites\n",
        "\n",
        "def recommend_for_user_lightgcn(model, adjacency_matrix, user_id_internal, train_matrix,\n",
        "                              idx_to_movie, movieId_to_title, device, k=20):\n",
        "    \"\"\"Generate recommendations for a specific user using LightGCN model.\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    num_users = model.num_users\n",
        "    num_items = model.num_items\n",
        "\n",
        "    # -----------------------------------------------------\n",
        "    # 2. Model predictions for unseen items\n",
        "    # -----------------------------------------------------\n",
        "    with torch.no_grad():\n",
        "        # Get embeddings\n",
        "        user_emb, item_emb = model(adjacency_matrix)\n",
        "\n",
        "        # Calculate scores for all items\n",
        "        u_emb = user_emb[user_id_internal]\n",
        "        scores = torch.matmul(u_emb, item_emb.T)\n",
        "\n",
        "        # Mask seen interactions\n",
        "        if hasattr(train_matrix, 'rows'):\n",
        "            # For LIL format\n",
        "            seen_items = set(train_matrix.rows[user_id_internal])\n",
        "        else:\n",
        "            # For CSR format\n",
        "            seen_items = set(train_matrix[user_id_internal].nonzero()[1])\n",
        "\n",
        "        for iid in seen_items:\n",
        "            scores[iid] = -float('inf')\n",
        "\n",
        "        # Get top-k recommendations\n",
        "        topk_values, topk_indices = torch.topk(scores, min(k, len(scores)))\n",
        "        top_items = topk_indices.cpu().numpy()\n",
        "        top_scores = topk_values.cpu().numpy()\n",
        "\n",
        "    # Convert to recommendations\n",
        "    recommendations = []\n",
        "    for iid, score in zip(top_items, top_scores):\n",
        "        if iid in idx_to_movie:\n",
        "            real_movie_id = idx_to_movie[iid]\n",
        "            title = movieId_to_title.get(real_movie_id, f\"Unknown {real_movie_id}\")\n",
        "            recommendations.append({\n",
        "                'item_idx': iid,\n",
        "                'title': title,\n",
        "                'score': float(score)\n",
        "            })\n",
        "        else:\n",
        "            recommendations.append({\n",
        "                'item_idx': iid,\n",
        "                'title': f\"Item {iid}\",\n",
        "                'score': float(score)\n",
        "            })\n",
        "\n",
        "    return recommendations\n",
        "\n",
        "def analyze_user_recommendations(user_id_internal, model, adjacency_matrix, train_matrix,\n",
        "                                user_to_idx, movie_to_idx, ratings_df, device, k=20):\n",
        "    \"\"\"Complete analysis for a user: top rated movies and recommendations.\"\"\"\n",
        "\n",
        "    # Load movie metadata\n",
        "    movieId_to_title = load_movie_metadata()\n",
        "\n",
        "    # Create reverse mappings\n",
        "    idx_to_user, idx_to_movie = create_reverse_mappings(user_to_idx, movie_to_idx)\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"ANALYSIS FOR USER (internal ID: {user_id_internal})\")\n",
        "    print(f\"Real user ID: {idx_to_user.get(user_id_internal, 'Unknown')}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # 1. Get user's top rated movies\n",
        "    if ratings_df is not None:\n",
        "        favorites = get_top_rated_movies(\n",
        "            user_id_internal, ratings_df, idx_to_user,\n",
        "            movie_to_idx, movieId_to_title, top_n=10\n",
        "        )\n",
        "\n",
        "        if favorites:\n",
        "            print(f\"\\n=== Top {len(favorites)} Highest-Rated Movies by User ===\")\n",
        "            for i, fav in enumerate(favorites, 1):\n",
        "                if fav['item_idx'] is not None:\n",
        "                    print(f\"{i:2}. {fav['title']} — rated {fav['rating']:.1f}\")\n",
        "                else:\n",
        "                    print(f\"{i:2}. {fav['title']} — rated {fav['rating']:.1f} (not in training data)\")\n",
        "        else:\n",
        "            print(\"\\nNo rating history found for this user\")\n",
        "\n",
        "    # 2. Get recommendations\n",
        "    recommendations = recommend_for_user_lightgcn(\n",
        "        model, adjacency_matrix, user_id_internal,\n",
        "        train_matrix, idx_to_movie, movieId_to_title, device, k=k\n",
        "    )\n",
        "\n",
        "    print(f\"\\n=== Model Recommendations (Top {len(recommendations)}) ===\")\n",
        "    for i, rec in enumerate(recommendations, 1):\n",
        "        print(f\"{i:2}. {rec['title']} — score {rec['score']:.4f}\")\n",
        "\n",
        "    return favorites if 'favorites' in locals() else None, recommendations\n",
        "\n",
        "def analyze_multiple_users(model, adjacency_matrix, train_matrix, user_to_idx,\n",
        "                          movie_to_idx, ratings_df, device, user_ids=None, k=20):\n",
        "    \"\"\"Analyze recommendations for multiple users.\"\"\"\n",
        "    if user_ids is None:\n",
        "        # Analyze users with test interactions (from your metrics calculator)\n",
        "        num_users = len(user_to_idx)\n",
        "        # Sample 5 random users\n",
        "        user_ids = np.random.choice(num_users, size=min(5, num_users), replace=False)\n",
        "\n",
        "    all_results = {}\n",
        "    for user_id in user_ids:\n",
        "        try:\n",
        "            favorites, recommendations = analyze_user_recommendations(\n",
        "                user_id, model, adjacency_matrix, train_matrix,\n",
        "                user_to_idx, movie_to_idx, ratings_df, device, k\n",
        "            )\n",
        "            all_results[user_id] = {\n",
        "                'favorites': favorites,\n",
        "                'recommendations': recommendations\n",
        "            }\n",
        "        except Exception as e:\n",
        "            print(f\"Error analyzing user {user_id}: {e}\")\n",
        "\n",
        "    return all_results\n",
        "\n",
        "def save_recommendations_to_csv(recommendations, filename=\"user_recommendations.csv\"):\n",
        "    \"\"\"Save recommendations to CSV file.\"\"\"\n",
        "    if not recommendations:\n",
        "        print(\"No recommendations to save\")\n",
        "        return\n",
        "\n",
        "    # Flatten the data\n",
        "    rows = []\n",
        "    for user_id, data in recommendations.items():\n",
        "        if data['recommendations']:\n",
        "            for rec in data['recommendations']:\n",
        "                rows.append({\n",
        "                    'user_id': user_id,\n",
        "                    'item_id': rec['item_idx'],\n",
        "                    'title': rec['title'],\n",
        "                    'score': rec['score']\n",
        "                })\n",
        "\n",
        "    if rows:\n",
        "        df = pd.DataFrame(rows)\n",
        "        df.to_csv(filename, index=False)\n",
        "        print(f\"Saved {len(df)} recommendations to {filename}\")\n",
        "    else:\n",
        "        print(\"No valid recommendations to save\")"
      ],
      "metadata": {
        "id": "D-AGqQaCOIRI"
      },
      "id": "D-AGqQaCOIRI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 12: Demo - Analyze recommendations for sample users\n",
        "def demo_recommendations():\n",
        "    \"\"\"Demonstrate recommendation analysis\"\"\"\n",
        "    print(\"Loading data for recommendation analysis...\")\n",
        "\n",
        "    # Reload data if needed\n",
        "    data_loader = PreprocessedDataLoader('/kaggle/input/dkr2025/')\n",
        "    data = data_loader.load_preprocessed_data()\n",
        "\n",
        "    # Load ratings for user history\n",
        "    try:\n",
        "        ratings_df = pd.read_csv(\"/kaggle/input/dkr2025/ratings.csv\")\n",
        "        print(f\"Loaded ratings data: {len(ratings_df):,} ratings\")\n",
        "    except:\n",
        "        print(\"Could not load ratings.csv, using train_ratings instead\")\n",
        "        ratings_df = data['train_ratings']\n",
        "        ratings_df = ratings_df.rename(columns={'user_idx': 'userId', 'movie_idx': 'movieId'})\n",
        "\n",
        "    # Load best model\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    if os.path.exists('best_model.pth'):\n",
        "        try:\n",
        "            checkpoint = torch.load('best_model.pth', weights_only=False, map_location=device)\n",
        "\n",
        "            # Recreate model\n",
        "            num_users = len(data['user_to_idx'])\n",
        "            num_movies = len(data['movie_to_idx'])\n",
        "\n",
        "            model = LightGCN(\n",
        "                num_users=num_users,\n",
        "                num_items=num_movies,\n",
        "                embedding_dim=64,\n",
        "                num_layers=3\n",
        "            ).to(device)\n",
        "\n",
        "            model.load_state_dict(checkpoint['model_state_dict'])\n",
        "            print(f\"Loaded best model from epoch {checkpoint['epoch']}\")\n",
        "\n",
        "            # Prepare adjacency matrix\n",
        "            adj_matrix = data['adj_matrix'].tocoo()\n",
        "            adjacency_matrix = SparseTensor(\n",
        "                row=torch.tensor(adj_matrix.row, dtype=torch.long),\n",
        "                col=torch.tensor(adj_matrix.col, dtype=torch.long),\n",
        "                value=torch.tensor(adj_matrix.data, dtype=torch.float32),\n",
        "                sparse_sizes=(adj_matrix.shape[0], adj_matrix.shape[1])\n",
        "            ).to(device)\n",
        "\n",
        "            # Analyze some users\n",
        "            print(\"\\n\" + \"=\"*60)\n",
        "            print(\"DEMONSTRATING RECOMMENDATIONS\")\n",
        "            print(\"=\"*60)\n",
        "\n",
        "            # Sample some users to analyze\n",
        "            sample_users = np.random.choice(num_users, size=min(3, num_users), replace=False)\n",
        "\n",
        "            results = analyze_multiple_users(\n",
        "                model=model,\n",
        "                adjacency_matrix=adjacency_matrix,\n",
        "                train_matrix=data['train_matrix'],\n",
        "                user_to_idx=data['user_to_idx'],\n",
        "                movie_to_idx=data['movie_to_idx'],\n",
        "                ratings_df=ratings_df,\n",
        "                device=device,\n",
        "                user_ids=sample_users,\n",
        "                k=15\n",
        "            )\n",
        "\n",
        "            # Save results\n",
        "            save_recommendations_to_csv(results, \"sample_recommendations.csv\")\n",
        "\n",
        "            print(\"\\n\" + \"=\"*60)\n",
        "            print(\"DEMONSTRATION COMPLETE\")\n",
        "            print(\"=\"*60)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in demo: {e}\")\n",
        "    else:\n",
        "        print(\"No trained model found. Please train the model first.\")\n",
        "\n",
        "# Run the demo\n",
        "demo_recommendations()"
      ],
      "metadata": {
        "id": "iRslym-BOj0P"
      },
      "id": "iRslym-BOj0P",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 8846792,
          "sourceId": 13885583,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 31193,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 13278.657577,
      "end_time": "2025-12-02T23:18:31.939060",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2025-12-02T19:37:13.281483",
      "version": "2.6.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}